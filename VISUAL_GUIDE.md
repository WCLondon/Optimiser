# Visual Guide: How the New Architecture Works

This guide uses simple diagrams to explain how the refactored system works.

## ğŸ—ï¸ Before vs After

### Before (Monolithic)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚         User Browser                â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Opens page, types input
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚      Streamlit Application          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. User types in input       â”‚  â”‚
â”‚  â”‚  2. App reruns immediately âŒ â”‚  â”‚
â”‚  â”‚  3. UI freezes                â”‚  â”‚
â”‚  â”‚  4. Optimization runs         â”‚  â”‚
â”‚  â”‚  5. UI unfreezes              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       PostgreSQL Database           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problems:**
- âŒ UI freezes during optimization
- âŒ Every keystroke triggers a rerun
- âŒ No caching of results
- âŒ Can't scale horizontally
- âŒ One user's heavy job blocks everyone

---

### After (Microservices)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Browser                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Submits form
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Streamlit Frontend                           â”‚
â”‚              (Port 8501)                                  â”‚
â”‚                                                           â”‚
â”‚  âœ… Form-based input (no rerun on typing)                â”‚
â”‚  âœ… Submit button triggers action                        â”‚
â”‚  âœ… UI stays responsive                                  â”‚
â”‚  âœ… Polls for job status                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ POST /jobs
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend                              â”‚
â”‚              (Port 8000)                                  â”‚
â”‚                                                           â”‚
â”‚  1. Receive job request                                   â”‚
â”‚  2. Hash inputs (deterministic)                          â”‚
â”‚  3. Check Redis cache first                              â”‚
â”‚  4. If cached: return immediately âš¡                     â”‚
â”‚  5. If not: create job in queue                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â”‚ Enqueue              â”‚ Check/Store
          â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Queue    â”‚    â”‚     Redis Cache          â”‚
â”‚                 â”‚    â”‚                          â”‚
â”‚  Job 1: pending â”‚    â”‚  cache:abc123 â†’ result   â”‚
â”‚  Job 2: running â”‚    â”‚  cache:def456 â†’ result   â”‚
â”‚  Job 3: pending â”‚    â”‚  (12 hour TTL)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Workers pull jobs
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RQ Workers                             â”‚
â”‚                    (2-4 instances)                        â”‚
â”‚                                                           â”‚
â”‚  Worker 1: Processing Job 2 ğŸ”„                           â”‚
â”‚  Worker 2: Waiting for jobs ğŸ’¤                           â”‚
â”‚                                                           â”‚
â”‚  âœ… Run in background                                    â”‚
â”‚  âœ… Can scale horizontally                               â”‚
â”‚  âœ… Isolate heavy computation                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Query data
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PostgreSQL Database                          â”‚
â”‚                                                           â”‚
â”‚  â€¢ Reference tables (Banks, Pricing, etc.)               â”‚
â”‚  â€¢ Submission history                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- âœ… UI never freezes
- âœ… No rerun on typing (form-based)
- âœ… Results cached for 12 hours
- âœ… Horizontal scaling (add more workers)
- âœ… Multiple users work simultaneously

---

## ğŸ”„ Job Lifecycle

### Scenario 1: Cache Hit (Instant Result)

```
User submits job with params: {lpa: "Winchester", demand: 10}
                    â”‚
                    â–¼
         Frontend â†’ Backend
                    â”‚
                    â–¼
         Hash params â†’ "abc123"
                    â”‚
                    â–¼
         Check Redis: cache:abc123
                    â”‚
                    â–¼
              âœ… FOUND!
                    â”‚
                    â–¼
         Return cached result
         (Response time: <50ms)
```

### Scenario 2: Cache Miss (New Job)

```
User submits job with params: {lpa: "Bristol", demand: 15}
                    â”‚
                    â–¼
         Frontend â†’ Backend
                    â”‚
                    â–¼
         Hash params â†’ "def456"
                    â”‚
                    â–¼
         Check Redis: cache:def456
                    â”‚
                    â–¼
              âŒ NOT FOUND
                    â”‚
                    â–¼
         Create job in queue
                    â”‚
                    â–¼
         Return job_id: "xyz789"
                    â”‚
                    â–¼
         Frontend starts polling
         GET /jobs/xyz789 every 1 second
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚
         â–¼                     â–¼
    status: queued       status: started
         â”‚                     â”‚
         â”‚                     â–¼
         â”‚              Worker processing...
         â”‚                     â”‚
         â”‚                     â–¼
         â”‚              Store result in cache
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
              status: finished
                    â”‚
                    â–¼
         Return result to frontend
         (Response time: 5-30 seconds)
```

---

## ğŸ“Š Request Flow Diagram

### Without Backend (Standalone Mode)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚ Enter data
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚ â—„â”€â”€â”€ Optimization runs here
â”‚                 â”‚      (UI freezes)
â”‚   app.py        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline:
0s  â”€â”€â”€â”€â–º User clicks Optimize
0s  â”€â”€â”€â”€â–º UI freezes â„ï¸
5s  â”€â”€â”€â”€â–º Still processing...
10s â”€â”€â”€â”€â–º Still processing...
15s â”€â”€â”€â”€â–º Done! UI unfreezes âœ…
```

### With Backend (New Mode)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚ Enter data
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚ â—„â”€â”€â”€ Just UI and polling
â”‚   (Frontend)    â”‚      (Never freezes!)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ HTTP API
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI      â”‚ â—„â”€â”€â”€ Job management
â”‚   (Backend)     â”‚      (Checks cache, queues jobs)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Redis       â”‚ â—„â”€â”€â”€ Queue + Cache
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RQ Workers    â”‚ â—„â”€â”€â”€ Actual optimization
â”‚   (2+ workers)  â”‚      (Heavy lifting)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline:
0s  â”€â”€â”€â”€â–º User clicks Optimize
0s  â”€â”€â”€â”€â–º Request sent to backend âš¡
0.1sâ”€â”€â”€â–º Job queued (UI still responsive âœ…)
1s â”€â”€â”€â”€â–º User can continue using UI ğŸ‰
2s â”€â”€â”€â”€â–º Worker starts processing
...     â–º User sees "Processing..." spinner
15s â”€â”€â”€â–º Job complete, result displayed âœ…
```

---

## ğŸ¯ Caching Strategy

### How Caching Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Input Parameters                        â”‚
â”‚  {                                                   â”‚
â”‚    "demand_df": {...},                              â”‚
â”‚    "target_lpa": "Winchester",                      â”‚
â”‚    "target_nca": "South Downs"                      â”‚
â”‚  }                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  JSON.stringify()     â”‚
         â”‚  (sorted keys)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         "{"demand_df":{...},"target_lpa":"Winchester",...}"
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SHA256 Hash         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         "a3f5b9c2e8d1..."
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Redis Key             â”‚
         â”‚ "cache:a3f5b9c2e8d1" â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Result stored for 12 hours (43200 seconds)
```

### Cache Hit Scenarios

```
Request 1 (New):
User A â†’ {lpa: "Winchester"} â†’ hash: abc123
         Check Redis â†’ NOT FOUND âŒ
         Create job â†’ Process â†’ Store in cache
         Response time: 15 seconds

Request 2 (Same params, User B):
User B â†’ {lpa: "Winchester"} â†’ hash: abc123
         Check Redis â†’ FOUND! âœ…
         Return cached result
         Response time: 50 milliseconds (300x faster!)

Request 3 (Different params):
User C â†’ {lpa: "Bristol"} â†’ hash: def456
         Check Redis â†’ NOT FOUND âŒ
         Create new job...
```

---

## ğŸ”¢ Scaling Example

### Before: Single Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Streamlit Process       â”‚
â”‚                              â”‚
â”‚  User 1: Processing job â³   â”‚
â”‚  User 2: Waiting... ğŸ˜´       â”‚
â”‚  User 3: Waiting... ğŸ˜´       â”‚
â”‚  User 4: Waiting... ğŸ˜´       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Max throughput: 1 job at a time
```

### After: Multiple Workers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Worker 1              â”‚
â”‚  User 1: Processing job â³   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Worker 2              â”‚
â”‚  User 2: Processing job â³   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Worker 3              â”‚
â”‚  User 3: Processing job â³   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Worker 4              â”‚
â”‚  Waiting for jobs... ğŸ’¤      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Max throughput: 4 jobs simultaneously
Can scale to 10, 20, 50+ workers!
```

---

## ğŸš€ Deployment Options Visualized

### Local Development

```
Your Computer
â”œâ”€â”€ Docker Desktop
â”‚   â”œâ”€â”€ Redis Container
â”‚   â”œâ”€â”€ Backend Container
â”‚   â”œâ”€â”€ Worker Containers (x2)
â”‚   â””â”€â”€ Frontend Container
â””â”€â”€ Browser â†’ http://localhost:8501

Command: make local-up
Cost: $0
```

### Cloud Run (Google Cloud)

```
Google Cloud
â”œâ”€â”€ Memorystore Redis
â”œâ”€â”€ Cloud Run: Backend
â”‚   â”œâ”€â”€ Min 1 instance
â”‚   â””â”€â”€ Max 10 instances (auto-scale)
â”œâ”€â”€ Compute Engine: Workers
â”‚   â””â”€â”€ 2 VMs (always on)
â”œâ”€â”€ Cloud Run: Frontend
â”‚   â”œâ”€â”€ Min 1 instance
â”‚   â””â”€â”€ Max 5 instances (auto-scale)
â””â”€â”€ Cloud SQL: PostgreSQL

Command: make deploy-all PROJECT_ID=your-project
Cost: ~$340/month
```

### Fly.io

```
Fly.io
â”œâ”€â”€ Upstash Redis
â”œâ”€â”€ Fly App: Backend
â”‚   â””â”€â”€ 2 instances
â”œâ”€â”€ Fly App: Workers
â”‚   â””â”€â”€ 2 instances
â”œâ”€â”€ Fly App: Frontend
â”‚   â””â”€â”€ 2 instances
â””â”€â”€ Fly Postgres

Command: flyctl deploy
Cost: ~$103/month
```

---

## ğŸ¨ UI Flow Comparison

### Old UI Flow (Blocking)

```
1. User enters data
   [Input box]

2. User clicks "Optimize"
   [Button]

3. â³ Page freezes
   (Cannot interact with anything)

4. Loading spinner appears
   ğŸŒ€ "Optimizing..."
   
5. Wait... wait... wait...
   (Could be 30+ seconds)

6. âœ… Results appear
   [Results table]
   
Total time with no interaction: 30 seconds
```

### New UI Flow (Non-blocking)

```
1. User enters data
   [Input box] âœ… Can still type

2. User clicks "Optimize"
   [Button]

3. âœ… Page stays responsive
   [Status: "Job submitted"]

4. Polling starts
   ğŸ”„ "Processing... (queued)"
   â†“
   ğŸ”„ "Processing... (started)"
   â†“
   ğŸ”„ "Processing... (90% done)"

5. Meanwhile, user can:
   - Scroll the page âœ…
   - Read documentation âœ…
   - Check other tabs âœ…
   - Prepare next request âœ…

6. âœ… Results appear
   [Results table]
   
Total time: Same, but user is never blocked!
```

---

## ğŸ“± Quick Reference

### Ports & URLs

| Service | Port | URL | Purpose |
|---------|------|-----|---------|
| Frontend | 8501 | http://localhost:8501 | Streamlit UI |
| Backend | 8000 | http://localhost:8000 | FastAPI API |
| API Docs | 8000 | http://localhost:8000/docs | Interactive docs |
| Redis | 6379 | (internal) | Queue & cache |

### Commands

| Task | Command |
|------|---------|
| Start all | `make local-up` |
| Stop all | `make local-down` |
| View logs | `make local-logs` |
| Test backend | `curl http://localhost:8000/health` |
| Access Redis | `make redis-cli` |
| Scale workers | `docker-compose scale worker=4` |

### File Structure

```
Optimiser/
â”œâ”€â”€ app.py                 # Original Streamlit app
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py            # FastAPI service
â”‚   â”œâ”€â”€ tasks.py          # Worker tasks
â”‚   â””â”€â”€ worker.py         # RQ worker
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ Dockerfile.worker
â”œâ”€â”€ docker-compose.yml     # Local orchestration
â”œâ”€â”€ Makefile              # Automation commands
â””â”€â”€ STEP_BY_STEP_GUIDE.md # This guide!
```

---

## âœ… Success Indicators

You know it's working when:

1. âœ… `make local-up` completes without errors
2. âœ… All 4 services show as "running" in `docker-compose ps`
3. âœ… http://localhost:8000/health returns `{"status": "ok"}`
4. âœ… http://localhost:8501 loads the Streamlit app
5. âœ… Clicking "Optimize" doesn't freeze the UI
6. âœ… A progress indicator appears while processing
7. âœ… Results appear after processing completes
8. âœ… Second identical request returns instantly (cached!)

---

## ğŸ“ Understanding by Analogy

Think of it like a restaurant:

**Before (Monolith):**
- One chef does everything
- Takes order, cooks, serves
- If cooking a big meal, no one else can order
- Kitchen freezes for everyone

**After (Microservices):**
- **Frontend** = Waiter (takes orders, serves results)
- **Backend** = Host (manages orders, checks if dish is ready)
- **Redis** = Kitchen ticket system + dish warmer
- **Workers** = Multiple chefs (cook in parallel)
- **PostgreSQL** = Recipe book

When you order:
1. Waiter takes order â†’ Frontend
2. Host checks warmer for pre-made dish â†’ Cache check
3. If not ready, ticket goes to kitchen â†’ Queue job
4. Chef cooks while you wait at table â†’ Worker processes
5. Waiter brings food when ready â†’ Display result

You can talk, browse menu while chef cooks!

---

That's it! You now understand how the new architecture works. Ready to implement it? Follow the [STEP_BY_STEP_GUIDE.md](STEP_BY_STEP_GUIDE.md)!
